{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "openai_api_key=config(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for converting raw unstructed data into a QA chain\n",
    "#### Indexing\n",
    "\n",
    "1. Loading: Initially, the data needs to be loaded. Unstructured data can be sourced from various platforms. Utilize the LangChain Integration Hub to explore the complete range of loaders. Each loader outputs the data as a LangChain Document.\n",
    "\n",
    "2. Splitting: Text splitters segment the Documents into specified sizes.\n",
    "\n",
    "3. Storage: A storage solution, often a vector store, is used to house and sometimes embed the splits.\n",
    "\n",
    "<img src=\"https://python.langchain.com/assets/images/rag_indexing-8160f90a90a33253d0154659cf7d453f.png\" width=\"1000\" height=\"450\">\n",
    "\n",
    "#### Retrieval and Generation\n",
    "\n",
    "4. Retrieval: The application fetches the splits from the storage, usually based on embeddings similar to the input question.\n",
    "\n",
    "5. Generation: A Language Model (LLM) generates an answer using a prompt that incorporates both the question and the retrieved data.\n",
    "\n",
    "<img src=\"https://python.langchain.com/assets/images/rag_retrieval_generation-1046a4668d6bb08786ef73c56d4f228a.png\" width=\"1000\" height=\"450\">\n",
    "\n",
    "#### Bonous\n",
    "6. Conversation (Extension): To facilitate multi-turn conversations, Memory can be added to the QA chain.\n",
    "\n",
    "### Q & A pipeline RAG\n",
    "\n",
    "Referrence: [Langchain](https://python.langchain.com/docs/use_cases/question_answering/)\n",
    "\n",
    "* RAG is a technique for augmenting LLM knowledge with additional data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Loading the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://aws.amazon.com/vi/what-is/langchain/\")\n",
    "\n",
    "corpus = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangChain là gì? – Giải thích về LangChain – AWS\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Chuyển đến nội dung chính\\n\\n\\n\\n\\n\\nNhấp vào đây để quay lại trang chủ Amazon Web Services\\n\\n\\n\\nLiên hệ với chúng tôi\\n Hỗ trợ\\xa0 \\nTiếng Việt\\xa0\\nTài khoản của tôi\\xa0\\n\\n\\n\\n\\n Đăng nhập\\n\\n\\n  Tạo tài khoản AWS \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nre:Invent\\nSản phẩm\\nGiải pháp\\nĐịnh giá\\nTài liệu\\nTìm hiểu\\nMạng lưới đối tác\\nAWS Marketplace\\nTiếp cận khách hàng\\nSự kiện\\nKhám phá thêm \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Đóng \\n\\n\\n\\nعربي\\nBahasa Indonesia\\nDeutsch\\nEnglish\\nEspañol\\nFrançais\\nItaliano\\nPortuguês\\n\\n\\n\\n\\nTiếng Việt\\nTürkçe\\nΡусский\\nไทย\\n日本語\\n한국어\\n中文 (简体)\\n中文 (繁體)\\n\\n\\n\\n\\n\\n Đóng \\n\\nHồ sơ của tôi\\nĐăng xuất khỏi AWS Builder ID\\nBảng điều khiển quản lý AWS\\nThiết lập tài khoản\\nQuản lý hóa đơn và chi phí\\nThông tin xác thực bảo mật\\nAWS Personal Health Dashboard\\n\\n\\n\\n Đóng \\n\\nTrung tâm Hỗ trợ\\nTrợ giúp từ chuyên gia\\nTrung tâm kiến thức\\nTổng quan về Hỗ trợ AWS\\nAWS re:Post\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNhấp vào đây để quay lại trang chủ Amazon Web Services\\n\\n\\n\\n\\n\\n\\n\\n  Bắt đầu sử dụng miễn phí \\n\\n\\n  Liên hệ với chúng tôi \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n re:Invent \\n Sản phẩm \\n Giải pháp \\n Giá cả \\n Giới thiệu AWS \\n Bắt đầu \\n Tài liệu \\n Đào tạo và chứng nhận \\n Trung tâm dành cho nhà phát triển \\n Thành công của khách hàng \\n Mạng lưới đối tác \\n AWS Marketplace \\n Hỗ trợ \\n AWS re:Post \\n Đăng nhập vào Bảng điều khiển \\n Tải xuống ứng dụng di động \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nĐiện toán đám mây là gì?\\nTrung tâm khái niệm về điện toán đám mây\\nAI tạo sinh\\nMáy học và trí tuệ nhân tạo\\n\\n\\nLangChain là gì?\\n\\n\\nTạo tài khoản AWS\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n             Khám phá các ưu đãi máy học miễn phí \\n           \\n\\n             Xây dựng, triển khai và chạy miễn phí ứng dụng máy học trên đám mây \\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n             Tìm hiểu về các dịch vụ máy học \\n           \\n\\n             Đổi mới sáng tạo nhanh hơn với bộ dịch vụ AI và ML toàn diện nhất \\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n             Duyệt xem các khóa đào tạo máy học \\n           \\n\\n             Bắt đầu đào tạo về máy học với nội dung được các chuyên gia AWS xây dựng \\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n             Đọc blog về máy học \\n           \\n\\n             Đọc các tin tức sản phẩm mới nhất và biện pháp thực hành tốt nhất về Máy học trên AWS \\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangChain là gì?\\nTại sao LangChain quan trọng? \\nLangChain hoạt động như thế nào? \\nLangChain có các thành phần cốt lõi nào? \\nAWS có thể giúp đáp ứng các yêu cầu LangChain của bạn như thế nào?\\xa0\\n\\n\\n\\n\\n\\n\\n\\nLangChain là gì?\\n\\nLangChain là một khung mã nguồn mở để xây dựng các ứng dụng dựa trên các mô hình ngôn ngữ lớn (LLM). LLM là các mô hình học sâu lớn được đào tạo trước trên khối lượng lớn dữ liệu có thể tạo ra câu trả lời cho các câu hỏi của người dùng, ví dụ như trả lời câu hỏi hoặc tạo hình ảnh từ lời nhắc dựa trên văn bản. LangChain cung cấp các công cụ và yếu tố trừu tượng để cải thiện khả năng tùy chỉnh, độ chính xác và mức độ liên quan của thông tin do các mô hình tạo ra. Ví dụ: nhà phát triển có thể sử dụng các thành phần LangChain để xây dựng chuỗi nhắc mới hoặc tùy chỉnh các mẫu hiện có. LangChain cũng bao gồm các thành phần cho phép LLM truy cập các tập dữ liệu mới mà không cần đào tạo lại.\\n\\n\\n\\n\\n\\n\\n\\nTại sao LangChain quan trọng? \\n\\nCác LLM phản hồi xuất sắc các lời nhắc trong bối cảnh chung nhưng gặp khó khăn trong một lĩnh vực cụ thể nếu chưa từng được đào tạo. Lời nhắc là các truy vấn mà mọi người sử dụng để tìm kiếm câu trả lời từ LLM. Ví dụ: LLM có thể trả lời câu hỏi về chi phí máy tính bằng cách đưa ra ước tính. Tuy nhiên, LLM không thể liệt kê giá của một mô hình máy tính cụ thể do công ty của bạn bán.\\xa0\\nĐể thực hiện việc đó, các kỹ sư máy học phải tích hợp LLM với các nguồn dữ liệu nội bộ của tổ chức và áp dụng tạo câu lệnh. Đây là biện pháp thực tế, trong đó nhà khoa học dữ liệu tinh chỉnh đầu vào cho một mô hình tạo sinh với cấu trúc và bối cảnh cụ thể.\\xa0\\nLangChain hợp lý hóa các bước trung gian để phát triển các ứng dụng phản hồi dữ liệu như vậy, giúp tạo câu lệnh hiệu quả hơn. LangChain được thiết kế để phát triển các ứng dụng đa dạng được hỗ trợ bởi các mô hình ngôn ngữ dễ dàng hơn, bao gồm chatbot, trả lời câu hỏi, tạo nội dung, trình tóm tắt, v.v.\\nCác phần sau đây trình bày về những lợi ích của LangChain.\\nTái sử dụng các mô hình ngôn ngữ\\nVới LangChain, các tổ chức có thể tái sử dụng LLM cho các ứng dụng cụ thể theo lĩnh vực mà không cần đào tạo lại hoặc tinh chỉnh. Các nhóm phát triển có thể xây dựng các ứng dụng phức tạp dựa trên tham chiếu thông tin độc quyền để tăng cường câu trả lời của mô hình. Ví dụ: bạn có thể sử dụng LangChain để xây dựng các ứng dụng đọc dữ liệu từ các tài liệu nội bộ được lưu trữ và tóm tắt thành các câu trả lời giao tiếp. Bạn có thể tạo một quy trình làm việc Kỹ thuật tạo sinh tăng cường truy xuất (RAG), qua đó cung cấp thông tin mới cho mô hình ngôn ngữ trong quá trình nhắc. Triển khai các quy trình công việc nhận biết ngữ cảnh như RAG giúp giảm ảo giác mô hình và cải thiện độ chính xác của câu trả lời.\\xa0\\nĐơn giản hóa việc phát triển AI\\nLangChain đơn giản hóa việc phát triển trí tuệ nhân tạo (AI) bằng cách trừu tượng hóa độ phức tạp của tích hợp nguồn dữ liệu và tinh chỉnh lời nhắc. Các nhà phát triển có thể tùy chỉnh chuỗi để xây dựng các ứng dụng phức tạp một cách nhanh chóng. Thay vì lập trình logic nghiệp vụ, các nhóm phần mềm có thể sửa đổi các mẫu và thư viện do LangChain cung cấp để giảm thời gian phát triển.\\xa0\\nHỗ trợ nhà phát triển\\nLangChain cung cấp công cụ cho các nhà phát triển AI để kết nối các mô hình ngôn ngữ với các nguồn dữ liệu bên ngoài. LangChain có mã nguồn mở và được hỗ trợ bởi một cộng đồng tích cực. Các tổ chức có thể sử dụng LangChain miễn phí và nhận được hỗ trợ từ các nhà phát triển khác thành thạo về khung này.\\n\\n\\n\\n\\n\\n\\n\\nLangChain hoạt động như thế nào? \\n\\nVới LangChain, các nhà phát triển có thể điều chỉnh linh hoạt mô hình ngôn ngữ cho các bối cảnh kinh doanh cụ thể bằng cách chỉ định các bước cần thiết để tạo ra kết quả mong muốn.\\xa0\\nChuỗi\\nChuỗi là nguyên tắc cơ bản chứa nhiều thành phần AI khác nhau trong LangChain để đưa ra câu trả lời nhận biết ngữ cảnh. Chuỗi là một loạt các hành động tự động từ truy vấn của người dùng đến đầu ra của mô hình. Ví dụ: các nhà phát triển có thể sử dụng chuỗi để:\\n\\nKết nối với các nguồn dữ liệu khác nhau.\\nTạo nội dung độc đáo.\\nDịch nhiều ngôn ngữ.\\nTrả lời các truy vấn của người dùng.\\xa0\\n\\nCác liên kết\\nChuỗi được hình thành từ các liên kết. Mỗi hành động được các nhà phát triển xâu chuỗi lại với nhau để tạo thành chuỗi được kết nối gọi là một liên kết. Với các liên kết, nhà phát triển có thể chia các tác vụ phức tạp thành nhiều tác vụ nhỏ hơn. Ví dụ về các liên kết bao gồm:\\n\\nĐịnh dạng đầu vào của người dùng.\\xa0\\nGửi truy vấn đến LLM.\\xa0\\nTruy xuất dữ liệu từ kho lưu trữ đám mây.\\nDịch từ ngôn ngữ này sang ngôn ngữ khác.\\n\\nTrong khung LangChain, một liên kết chấp nhận đầu vào từ người dùng và chuyển đầu vào đó đến các thư viện LangChain để xử lý. LangChain cũng cho phép sắp xếp lại liên kết để tạo các quy trình làm việc AI khác nhau.\\xa0\\nTổng quan\\nĐể sử dụng LangChain, các nhà phát triển cài đặt khung trong Python với lệnh sau:\\npip install langchain\\xa0\\nSau đó, các nhà phát triển sử dụng các khối xây dựng chuỗi hoặc Ngôn ngữ biểu thức LangChain (LCEL) để soạn chuỗi bằng các lệnh lập trình đơn giản. Hàm chain() truyền các đối số của liên kết đến các thư viện. Lệnh execute() truy xuất kết quả. Các nhà phát triển có thể truyền kết quả liên kết hiện tại đến liên kết sau đó hoặc trả về dưới dạng đầu ra cuối cùng.\\xa0\\nDưới đây là một ví dụ về chức năng chuỗi chatbot trả về chi tiết sản phẩm bằng nhiều ngôn ngữ.\\nchain([\\nretrieve_data_from_product_database().\\nsend_data_to_language_model().\\n\\xa0\\xa0\\xa0format_output_in_a_list().\\n\\xa0\\xa0translate_output_in_target_language()\\n])\\n\\n\\n\\n\\n\\n\\n\\n\\nLangChain có các thành phần cốt lõi nào? \\n\\nKhi sử dụng LangChain, các nhóm phần mềm có thể xây dựng các hệ thống mô hình ngôn ngữ nhận biết ngữ cảnh với các mô-đun sau.\\xa0\\nGiao diện LLM\\nLangChain cung cấp các API mà nhà phát triển có thể dùng để kết nối và truy vấn LLM từ mã tương ứng. Các nhà phát triển có thể giao tiếp với các mô hình công khai và độc quyền như GPT, Bard và PaLM thông qua LangChain bằng cách thực hiện các lệnh gọi API đơn giản thay vì viết mã phức tạp.\\nMẫu nhắc\\nMẫu nhắc là cấu trúc được tạo sẵn mà các nhà phát triển sử dụng để định dạng các truy vấn cho mô hình AI một cách nhất quán và chính xác. Các nhà phát triển có thể tạo mẫu nhắc cho các ứng dụng chatbot, học với ít dữ liệu đào tạo hoặc đưa ra hướng dẫn cụ thể cho các mô hình ngôn ngữ. Hơn nữa, họ có thể sử dụng lại các mẫu trên các ứng dụng và mô hình ngôn ngữ khác nhau.\\xa0\\nĐại lý\\nCác nhà phát triển sử dụng các công cụ và thư viện do LangChain cung cấp để soạn và tùy chỉnh các chuỗi hiện có cho các ứng dụng phức tạp. Tác tử là một chuỗi đặc biệt nhắc mô hình ngôn ngữ quyết định trình tự phù hợp nhất để trả lời truy vấn. Khi sử dụng tác tử, các nhà phát triển cung cấp đầu vào của người dùng, các công cụ sẵn có và các bước trung gian khả thi để đạt được kết quả mong muốn. Sau đó, mô hình ngôn ngữ trả về một chuỗi hành động khả thi mà ứng dụng có thể thực hiện.\\xa0\\xa0\\nCác mô-đun truy xuất\\nLangChain cho phép xây dựng kiến trúc cho các hệ thống RAG bằng nhiều công cụ để chuyển đổi, lưu trữ, tìm kiếm và truy xuất thông tin tinh chỉnh các câu trả lời của mô hình ngôn ngữ. Các nhà phát triển có thể tạo các phép biểu diễn ngữ nghĩa cho thông tin bằng phép nhúng từ và lưu trữ trong cơ sở dữ liệu véc-tơ cục bộ hoặc đám mây.\\xa0\\nBộ nhớ\\nMột số ứng dụng mô hình ngôn ngữ giao tiếp tinh chỉnh câu trả lời bằng thông tin được gọi lại từ các tương tác trước đây. LangChain cho phép các nhà phát triển gộp khả năng bộ nhớ vào hệ thống của họ. LangChain hỗ trợ:\\n\\nHệ thống bộ nhớ đơn giản gọi lại các cuộc trò chuyện gần đây nhất.\\xa0\\nCấu trúc bộ nhớ phức tạp phân tích các tin nhắn trước đây để trả về kết quả phù hợp nhất.\\xa0\\n\\nLệnh gọi lại\\nLệnh gọi lại là mã mà các nhà phát triển đặt trong ứng dụng của họ để ghi bản ghi, giám sát và truyền phát các sự kiện cụ thể trong hoạt động của LangChain. Ví dụ: các nhà phát triển có thể theo dõi thời điểm một chuỗi được gọi lần đầu và các lỗi gặp phải khi thực hiện lệnh gọi lại.\\xa0\\n\\n\\n\\n\\n\\n\\n\\nAWS có thể giúp đáp ứng các yêu cầu LangChain của bạn như thế nào?\\xa0\\n\\nThông qua Amazon Bedrock, Amazon Kendra, Amazon SageMaker JumpStart, LangChain và LLM của mình, bạn có thể xây dựng các ứng dụng trí tuệ nhân tạo tạo sinh (AI tạo sinh) có độ chính xác cao trên dữ liệu doanh nghiệp. LangChain là giao diện gắn kết các thành phần này lại với nhau:\\n\\nAmazon Bedrock là dịch vụ được quản lý mà các tổ chức có thể dựa vào đó để xây dựng và triển khai các ứng dụng AI tạo sinh. Bạn có thể sử dụng Amazon Bedrock để thiết lập mô hình thế hệ mà bạn truy cập từ LangChain.\\xa0\\nAmazon Kendra là dịch vụ được máy học (ML) hỗ trợ, giúp các tổ chức thực hiện tìm kiếm nội bộ. Bạn có thể kết nối Amazon Kendra với LangChain, vốn sử dụng dữ liệu từ cơ sở dữ liệu độc quyền để tinh chỉnh đầu ra mô hình ngôn ngữ.\\xa0\\nAmazon SageMaker Jumpstart là trung tâm ML cung cấp các thuật toán được tạo sẵn và các mô hình nền tảng mà các nhà phát triển có thể triển khai nhanh chóng. Bạn có thể lưu trữ các mô hình nền tảng trên SageMaker Jumpstart và nhắc các mô hình này từ LangChain.\\xa0\\n\\nBắt đầu sử dụng LangChain trên AWS bằng cách tạo tài khoản ngay hôm nay.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Các bước tiếp theo trên AWS\\n\\n\\n\\n\\n\\n\\n\\n\\n           Tham khảo các tài nguyên bổ sung liên quan đến sản phẩm \\n         \\n Đổi mới sáng tạo nhanh hơn với bộ dịch vụ AI và ML toàn diện nhất\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n           Đăng ký tài khoản miễn phí \\n         \\n\\nNhận ngay quyền sử dụng Bậc miễn phí của AWS.\\n\\n Đăng ký\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n           Bắt đầu xây dựng trong bảng điều khiển \\n         \\n\\nBắt đầu xây dựng trong AWS Management Console.\\n\\n Đăng nhập\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Đăng nhập vào bảng điều khiển \\n\\n Tìm hiểu về AWS\\n\\nAWS là gì?\\nĐiện toán đám mây là gì?\\nSự hòa nhập, đa dạng và công bằng của AWS\\nDevOps là gì?\\nBộ chứa là gì?\\nKho dữ liệu là gì?\\nKhả năng bảo mật của Đám mây AWS\\nThông tin mới\\nBlog\\nThông cáo báo chí\\n\\n\\n\\n Tài nguyên dành cho AWS\\n\\nBắt đầu\\nĐào tạo và chứng nhận\\nThư viện giải pháp AWS\\nTrung tâm kiến trúc\\nCâu hỏi thường gặp về sản phẩm và kỹ thuật\\nBáo cáo của chuyên gia phân tích\\nĐối tác của AWS\\n\\n\\n\\n Nhà phát triển trên AWS\\n\\nTrung tâm dành cho nhà phát triển\\nSDK và Công cụ\\n.NET trên AWS\\nPython trên AWS\\nJava trên AWS\\nPHP trên AWS\\nJavaScript trên AWS\\n\\n\\n\\n Trợ giúp\\n\\nLiên hệ với chúng tôi\\nNhận trợ giúp từ chuyên gia\\nNộp phiếu hỗ trợ\\nAWS re:Post\\nTrung tâm kiến thức\\nTổng quan về AWS Support\\nPháp lý\\nViệc làm tại AWS\\n\\n\\n\\n\\n\\n\\n\\n  Tạo tài khoản AWS \\n\\n\\n\\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\n         Amazon là một công ty làm việc bình đẳng: \\n         không phân biệt Dân tộc thiểu số / Nữ giới / Người khuyết tật / Cựu chiến binh / Bản dạng giới / Khuynh hướng tình dục / Tuổi tác.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNgôn ngữ\\nعربي\\nBahasa Indonesia\\nDeutsch\\nEnglish\\nEspañol\\nFrançais\\nItaliano\\nPortuguês\\nTiếng Việt\\nTürkçe\\nΡусский\\nไทย\\n日本語\\n한국어\\n中文 (简体)\\n中文 (繁體)\\n\\n\\n\\n\\n\\n\\n\\n\\nBảo mật\\n|\\nĐiều khoản áp dụng cho trang web\\n|\\n Tùy chọn cookie \\n|\\n© 2023, Amazon Web Services, Inc. hoặc các chi nhánh của Amazon. Bảo lưu mọi quyền.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Ngừng hỗ trợ cho Internet Explorer\\n Tôi hiểu \\n\\n\\n       AWS sẽ ngừng hỗ trợ cho Internet Explorer vào 07/31/2022. Các trình duyệt được hỗ trợ là Chrome, Firefox, Edge và Safari. \\n      Tìm hiểu thêm »\\n\\n\\nTôi hiểu\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://aws.amazon.com/vi/what-is/langchain/', 'title': 'LangChain là gì? – Giải thích về LangChain – AWS', 'description': 'Khái niệm về LangChain, cách thức và lý do các doanh nghiệp sử dụng LangChain, cũng như cách sử dụng LangChain với AWS.', 'language': 'vi-VN'})]\n"
     ]
    }
   ],
   "source": [
    "# print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Splitting the Document into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'cl100k_base'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Set up token encoding for the GPT-3.5 Turbo model\n",
    "tiktoken.encoding_for_model('gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "# Define a function to calculate the token length of a given text\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "# tiktoken_len(\"Dentin decay: Dentin is the layer just beneath your tooth enamel.\")\n",
    "tiktoken_len(\"LangChain là một khung mã nguồn mở để xây dựng các ứng dụng dựa trên các mô hình ngôn ngữ lớn (LLM).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nParams:\\n    1. chunk_size: size of each chunk of text.\\n    2. chunk_overlap: each chunk will overlap with the previous chunk.\\n    3. length_function: the length of the text\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialize the text splitter with specified parameters\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 20,\n",
    "    length_function = tiktoken_len\n",
    ")\n",
    "\"\"\"\n",
    "Params:\n",
    "    1. chunk_size: size of each chunk of text.\n",
    "    2. chunk_overlap: each chunk will overlap with the previous chunk.\n",
    "    3. length_function: the length of the text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the loaded document into smaller chunks\n",
    "chunks = text_splitter.split_documents(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
